breaks=color_breaks,
# color key + density info
key=TRUE,
keysize=1.0, symkey=FALSE, density.info='none',
trace='none',
# row/column labeling | plot layout
labRow=major_names,
labCol=major_names,
margins=c(30,30),
#lmat=rbind( c(0, 3), c(2,1), c(0,4) ), lhei=c(0.1, 4, 0.1 ), lwid=c(1,2),
)
png(paste(pref,'_MvsM_hellinger_vem_est_',toString(K),'.png',sep=""), width=900, height=900, res=300, pointsize=2)
heatmap.2(distHellinger( major_vs_topic[["VEM_est"]],major_vs_topic[["VEM_est"]] ),
main="VEM alpha estimated",
# dendogram control
dendrogram ='none',
distfun=dist,
hclustfun=function(c){hclust(c, method='mcquitty')},
# data scaling
scale="none",
cexRow=2,cexCol=2,
# colors
col=colorRampPalette(c('red','yellow','blue'))(n_colorbins-1),
breaks=color_breaks,
# color key + density info
key=TRUE,
keysize=1.0, symkey=FALSE, density.info='none',
trace='none',
# row/column labeling | plot layout
labRow=major_names,
labCol=major_names,
margins=c(30,30),
#lmat=rbind( c(0, 3), c(2,1), c(0,4) ), lhei=c(0.1, 4, 0.1 ), lwid=c(1,2),
)
dev.off()
png(paste(pref,'_MvsM_hellinger_vem_est_',toString(K),'.png',sep=""), width=900, height=900, res=300, pointsize=2)
heatmap.2(distHellinger( major_vs_topic[["VEM_est"]],major_vs_topic[["VEM_est"]] ),
main="VEM alpha estimated",
# dendogram control
dendrogram ='none',
distfun=dist,
hclustfun=function(c){hclust(c, method='mcquitty')},
# data scaling
scale="none",
cexRow=2,cexCol=2,
# colors
col=colorRampPalette(c('red','yellow','blue'))(n_colorbins-1),
RowSideColors=colorRampPalette(c('red','yellow','blue'))(n_majors),
breaks=color_breaks,
# color key + density info
key=TRUE,
keysize=1.0, symkey=FALSE, density.info='none',
trace='none',
# row/column labeling | plot layout
labRow=major_names,
labCol=major_names,
margins=c(30,30),
#lmat=rbind( c(0, 3), c(2,1), c(0,4) ), lhei=c(0.1, 4, 0.1 ), lwid=c(1,2),
)
dev.off()
png(paste(pref,'_MvsM_hellinger_vem_est_',toString(K),'.png',sep=""), width=900, height=900, res=400, pointsize=2)
heatmap.2(distHellinger( major_vs_topic[["VEM_est"]],major_vs_topic[["VEM_est"]] ),
main="VEM alpha estimated",
# dendogram control
dendrogram ='none',
distfun=dist,
hclustfun=function(c){hclust(c, method='mcquitty')},
# data scaling
scale="none",
cexRow=2,cexCol=2,
# colors
col=colorRampPalette(c('red','yellow','blue'))(n_colorbins-1),
breaks=color_breaks,
# color key + density info
key=TRUE,
keysize=1.5, symkey=FALSE, density.info='none',
trace='none',
# row/column labeling | plot layout
labRow=major_names,
labCol=major_names,
margins=c(30,30),
#lmat=rbind( c(0, 3), c(2,1), c(0,4) ), lhei=c(0.1, 4, 0.1 ), lwid=c(1,2),
)
dev.off()
png(paste(pref,'_MvsM_vem_est_',toString(K),'.png',sep=""), width=900, height=900, res=300, pointsize=2)
heatmap.2(cor(t(major_vs_topic[["VEM_est"]])),
main="VEM alpha estimated",
# dendogram control
dendrogram ='none',
distfun=dist,
hclustfun=function(c){hclust(c, method='mcquitty')},
# data scaling
scale="none",
cexRow=2,cexCol=2,
# colors
col=colorpanel(5000,'blue','green','red'),
# color key + density info
key=FALSE,
keysize=1.0, symkey=FALSE, density.info='none',
trace='none',
# row/column labeling | plot layout
margins=c(30,30),
#lmat=rbind( c(0, 3), c(2,1), c(0,4) ), lhei=c(0.1, 4, 0.1 ), lwid=c(0.2,4),
)
dev.off()
png(paste(pref,'_MvsM_vem_fix_',toString(K),'.png',sep=""), width=900, height=900, res=300, pointsize=2)
heatmap.2(cor(t(major_vs_topic[["VEM_fix"]])),
main="VEM alpha fixed",
# dendogram control
dendrogram ='none',
distfun=dist,
hclustfun=function(c){hclust(c, method='mcquitty')},
# data scaling
scale="none",
cexRow=2,cexCol=2,
# colors
col=colorpanel(5000,'blue','green','red'),
# color key + density info
key=FALSE,
keysize=1.0, symkey=FALSE, density.info='none',
trace='none',
# row/column labeling | plot layout
margins=c(30,30),
#lmat=rbind( c(0, 3), c(2,1), c(0,4) ), lhei=c(0.1, 4, 0.1 ), lwid=c(0.2,4),
)
dev.off()
png(paste(pref,'_MvsM_gibbs_',toString(K),'.png',sep=""), width=900, height=900, res=300, pointsize=2)
heatmap.2(cor(t(major_vs_topic[["Gibbs"]])),
main="Gibbs",
# dendogram control
dendrogram ='none',
distfun=dist,
hclustfun=function(c){hclust(c, method='mcquitty')},
# data scaling
scale="none",
cexRow=2,cexCol=2,
# colors
col=colorpanel(5000,'blue','green','red'),
# color key + density info
key=FALSE,
keysize=1.0, symkey=FALSE, density.info='none',
trace='none',
# row/column labeling | plot layout
margins=c(30,30),
#lmat=rbind( c(0, 3), c(2,1), c(0,4) ), lhei=c(0.1, 4, 0.1 ), lwid=c(0.2,4),
)
dev.off()
rm(list=ls())
library(topicmodels)
library(lda)
library(rjson)
library(gplots)
library(foreach)
getDocs <- function(x){
documents <- list()
for(i in 1:length(x)){
doc <- strsplit(x[i], ' ')[[1]]
if(strtoi(doc[1]) > 0) {
matrix_temp <- matrix(1:(strtoi(doc[1])*2), 2)
for(j in 2:length(doc)){
ind_freq <- doc[j]
ind_freq <- strsplit(ind_freq, ':')
ind_freq <- ind_freq[[1]]
matrix_temp[1, j-1] <- strtoi(ind_freq[1])
matrix_temp[2, j-1] <- strtoi(ind_freq[2])
}
documents <- c( documents, list( matrix_temp ) )
}
}
return(documents)
}
getMbyD <- function(x,wc){
res <- list()
for(i in 1:length(x)){
item <- x[i]
item <- strsplit(item, ',')[[1]]
doc <- strsplit(wc[i], ' ')[[1]]
if(strtoi(doc[1]) > 0) {
res <- c(res, list(item))
}
}
return(res)
}
#######################################################################################
#######################################################################################
# ENV SETUP
pref_path <- getwd() # /home/<user>/
count_pardir <- paste(pref_path,'/empanadas/dataR/counts/',sep='')
#
#######################################################################################
## set which data to use
NE <- 0 # 0: NE_sp | 1: NE_sp_hmm | 2: FULL
if(NE==0){
ne_counts <- paste(count_pardir,'NE_ene_ing/',sep='')
ne_wc   <- scan(paste(ne_counts  ,'word_counts.dat',sep=''), what='', sep = '\n')
ne_documents   <- getDocs(ne_wc)
ne_vocab   <- scan(paste(ne_counts  ,'vocab.dat',sep=''), what='', sep = '\n')
ne_major_by_doc   <- scan(paste(ne_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
ne_major_by_doc   <- getMbyD(ne_major_by_doc,ne_wc)
pref <-'ne'
major_by_doc <- ne_major_by_doc
documents <- ne_documents
vocab <- ne_vocab
}else if(NE==2){
full_counts <- paste(count_pardir,'full_ene_ing/',sep='')
full_wc <- scan(paste(full_counts,'word_counts.dat',sep=''), what='', sep = '\n')
full_documents <- getDocs(full_wc)
full_vocab <- scan(paste(full_counts,'vocab.dat',sep=''), what='', sep = '\n')
full_major_by_doc <- scan(paste(full_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
full_major_by_doc <- getMbyD(full_major_by_doc,full_wc)
pref <- 'full'
major_by_doc <- full_major_by_doc
documents <- full_documents
vocab <- full_vocab
}else{
ne_counts <- paste(count_pardir,'NE_ene_ing_sp_hmm/',sep='')
ne_wc   <- scan(paste(ne_counts  ,'word_counts.dat',sep=''), what='', sep = '\n')
ne_documents   <- getDocs(ne_wc)
ne_vocab   <- scan(paste(ne_counts  ,'vocab.dat',sep=''), what='', sep = '\n')
ne_major_by_doc   <- scan(paste(ne_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
ne_major_by_doc   <- getMbyD(ne_major_by_doc,ne_wc)
pref <-'ne_hmm'
major_by_doc <- ne_major_by_doc
documents <- ne_documents
vocab <- ne_vocab
}
#######################################################################################
THR = 45
major_map    <- fromJSON(file=paste(count_pardir,'map_major_eng.json',sep=''))
major_counts <- fromJSON(file=paste(count_pardir,'major_counts_eng.json',sep=''))
filtered_docs = list()
filtered_major_by_doc = list()
index_filter_mc = sapply(major_counts,function(x) return(x>THR))
filtered_major_counts = major_counts[index_filter_mc]
n_majors     <- length(filtered_major_counts)
major_names  <- names(filtered_major_counts)
#reset counts for every major
major_counts <- lapply(major_counts,function(x) return(0))
# count majors
for (i in 1:length(documents)){
foreach(major=major_by_doc[[i]])%do% {
cc = major_counts[[ major_map[[major]] ]]
major_counts[[ major_map[[major]] ]] = cc + 1
}
}
filtered_major_counts = major_counts[index_filter_mc]
## filter by freq_major
p=1
for (i in 1:length(documents)){
high_freq = FALSE
major_list = c()
foreach(major=major_by_doc[[i]])%do% {
if(major_counts[[major_map[[major]] ]]>THR){
high_freq = TRUE
major_list = c(major_list,major)
}
}
if(high_freq){
filtered_docs = c(filtered_docs,documents[i])
filtered_major_by_doc[[p]] = major_list
p=p+1
}
}
pref_path
count_pardir
setwd(ne_counts)
ne_counts
rm(list=ls())
rm(list=ls())
library(topicmodels)
library(lda)
library(rjson)
library(gplots)
library(foreach)
getDocs <- function(x){
documents <- list()
for(i in 1:length(x)){
doc <- strsplit(x[i], ' ')[[1]]
if(strtoi(doc[1]) > 0) {
matrix_temp <- matrix(1:(strtoi(doc[1])*2), 2)
for(j in 2:length(doc)){
ind_freq <- doc[j]
ind_freq <- strsplit(ind_freq, ':')
ind_freq <- ind_freq[[1]]
matrix_temp[1, j-1] <- strtoi(ind_freq[1])
matrix_temp[2, j-1] <- strtoi(ind_freq[2])
}
documents <- c( documents, list( matrix_temp ) )
}
}
return(documents)
}
getMbyD <- function(x,wc){
res <- list()
for(i in 1:length(x)){
item <- x[i]
item <- strsplit(item, ',')[[1]]
doc <- strsplit(wc[i], ' ')[[1]]
if(strtoi(doc[1]) > 0) {
res <- c(res, list(item))
}
}
return(res)
}
#######################################################################################
#######################################################################################
# ENV SETUP
pref_path <- getwd() # /home/<user>/
count_pardir <- paste(pref_path,'/empanadas/dataR/counts/',sep='')
#
#######################################################################################
## set which data to use
NE <- 0 # 0: NE_sp | 1: NE_sp_hmm | 2: FULL
if(NE==0){
ne_counts <- paste(count_pardir,'NE_ene_ing/',sep='')
ne_wc   <- scan(paste(ne_counts  ,'word_counts.dat',sep=''), what='', sep = '\n')
ne_documents   <- getDocs(ne_wc)
ne_vocab   <- scan(paste(ne_counts  ,'vocab.dat',sep=''), what='', sep = '\n')
ne_major_by_doc   <- scan(paste(ne_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
ne_major_by_doc   <- getMbyD(ne_major_by_doc,ne_wc)
ne_title_map <- scan(paste(ne_counts  ,'title_map.dat',sep=''), what='', sep = '\n')
pref <-'ne'
major_by_doc <- ne_major_by_doc
documents <- ne_documents
vocab <- ne_vocab
title_map <- ne_title_map
# set NE wd
setwd(ne_counts)
}else if(NE==2){
full_counts <- paste(count_pardir,'full_ene_ing/',sep='')
full_wc <- scan(paste(full_counts,'word_counts.dat',sep=''), what='', sep = '\n')
full_documents <- getDocs(full_wc)
full_vocab <- scan(paste(full_counts,'vocab.dat',sep=''), what='', sep = '\n')
full_major_by_doc <- scan(paste(full_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
full_major_by_doc <- getMbyD(full_major_by_doc,full_wc)
pref <- 'full'
major_by_doc <- full_major_by_doc
documents <- full_documents
vocab <- full_vocab
}else{
ne_counts <- paste(count_pardir,'NE_ene_ing_sp_hmm/',sep='')
ne_wc   <- scan(paste(ne_counts  ,'word_counts.dat',sep=''), what='', sep = '\n')
ne_documents   <- getDocs(ne_wc)
ne_vocab   <- scan(paste(ne_counts  ,'vocab.dat',sep=''), what='', sep = '\n')
ne_major_by_doc   <- scan(paste(ne_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
ne_major_by_doc   <- getMbyD(ne_major_by_doc,ne_wc)
pref <-'ne_hmm'
major_by_doc <- ne_major_by_doc
documents <- ne_documents
vocab <- ne_vocab
}
#######################################################################################
THR = 45
major_map    <- fromJSON(file=paste(count_pardir,'map_major_eng.json',sep=''))
major_counts <- fromJSON(file=paste(count_pardir,'major_counts_eng.json',sep=''))
filtered_docs = list()
filtered_major_by_doc = list()
filtered_title_map = list()
index_filter_mc = sapply(major_counts,function(x) return(x>THR))
filtered_major_counts = major_counts[index_filter_mc]
n_majors     <- length(filtered_major_counts)
major_names  <- names(filtered_major_counts)
#reset counts for every major
major_counts <- lapply(major_counts,function(x) return(0))
# count majors
for (i in 1:length(documents)){
foreach(major=major_by_doc[[i]])%do% {
cc = major_counts[[ major_map[[major]] ]]
major_counts[[ major_map[[major]] ]] = cc + 1
}
}
filtered_major_counts = major_counts[index_filter_mc]
## filter by freq_major
p=1
for (i in 1:length(documents)){
high_freq = FALSE
major_list = c()
foreach(major=major_by_doc[[i]])%do% {
if(major_counts[[major_map[[major]] ]]>THR){
high_freq = TRUE
major_list = c(major_list,major)
}
}
if(high_freq){
filtered_docs = c(filtered_docs,documents[i])
filtered_major_by_doc[[p]] = major_list
filtered_title_map = c(filtered_title_map,title_map[i])
p=p+1
}
}
rm(list=ls())
library(topicmodels)
library(lda)
library(rjson)
library(gplots)
library(foreach)
getDocs <- function(x){
documents <- list()
for(i in 1:length(x)){
doc <- strsplit(x[i], ' ')[[1]]
if(strtoi(doc[1]) > 0) {
matrix_temp <- matrix(1:(strtoi(doc[1])*2), 2)
for(j in 2:length(doc)){
ind_freq <- doc[j]
ind_freq <- strsplit(ind_freq, ':')
ind_freq <- ind_freq[[1]]
matrix_temp[1, j-1] <- strtoi(ind_freq[1])
matrix_temp[2, j-1] <- strtoi(ind_freq[2])
}
documents <- c( documents, list( matrix_temp ) )
}
}
return(documents)
}
getMbyD <- function(x,wc){
res <- list()
for(i in 1:length(x)){
item <- x[i]
item <- strsplit(item, ',')[[1]]
doc <- strsplit(wc[i], ' ')[[1]]
if(strtoi(doc[1]) > 0) {
res <- c(res, list(item))
}
}
return(res)
}
#######################################################################################
#######################################################################################
# ENV SETUP
pref_path <- getwd() # /home/<user>/
count_pardir <- paste(pref_path,'/empanadas/dataR/counts/',sep='')
count_dir <- ''
#
#######################################################################################
## set which data to use
NE <- 0 # 0: NE_sp | 1: NE_sp_hmm | 2: FULL
if(NE==0){
ne_counts <- paste(count_pardir,'NE_ene_ing/',sep='')
ne_wc   <- scan(paste(ne_counts  ,'word_counts.dat',sep=''), what='', sep = '\n')
ne_documents   <- getDocs(ne_wc)
ne_vocab   <- scan(paste(ne_counts  ,'vocab.dat',sep=''), what='', sep = '\n')
ne_major_by_doc   <- scan(paste(ne_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
ne_major_by_doc   <- getMbyD(ne_major_by_doc,ne_wc)
ne_title_map <- scan(paste(ne_counts  ,'title_map.dat',sep=''), what='', sep = '\n')
pref <-'ne'
major_by_doc <- ne_major_by_doc
documents <- ne_documents
vocab <- ne_vocab
title_map <- ne_title_map
count_dir <- ne_counts
}else if(NE==2){
full_counts <- paste(count_pardir,'full_ene_ing/',sep='')
full_wc <- scan(paste(full_counts,'word_counts.dat',sep=''), what='', sep = '\n')
full_documents <- getDocs(full_wc)
full_vocab <- scan(paste(full_counts,'vocab.dat',sep=''), what='', sep = '\n')
full_major_by_doc <- scan(paste(full_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
full_major_by_doc <- getMbyD(full_major_by_doc,full_wc)
pref <- 'full'
major_by_doc <- full_major_by_doc
documents <- full_documents
vocab <- full_vocab
}else{
ne_counts <- paste(count_pardir,'NE_ene_ing_sp_hmm/',sep='')
ne_wc   <- scan(paste(ne_counts  ,'word_counts.dat',sep=''), what='', sep = '\n')
ne_documents   <- getDocs(ne_wc)
ne_vocab   <- scan(paste(ne_counts  ,'vocab.dat',sep=''), what='', sep = '\n')
ne_major_by_doc   <- scan(paste(ne_counts  ,'majors_by_doc.dat',sep=''), what='',sep = '\n')
ne_major_by_doc   <- getMbyD(ne_major_by_doc,ne_wc)
pref <-'ne_hmm'
major_by_doc <- ne_major_by_doc
documents <- ne_documents
vocab <- ne_vocab
}
#######################################################################################
THR = 45
major_map    <- fromJSON(file=paste(count_pardir,'map_major_eng.json',sep=''))
major_counts <- fromJSON(file=paste(count_pardir,'major_counts_eng.json',sep=''))
filtered_docs = list()
filtered_major_by_doc = list()
filtered_title_map = list()
index_filter_mc = sapply(major_counts,function(x) return(x>THR))
filtered_major_counts = major_counts[index_filter_mc]
n_majors     <- length(filtered_major_counts)
major_names  <- names(filtered_major_counts)
#reset counts for every major
major_counts <- lapply(major_counts,function(x) return(0))
# count majors
for (i in 1:length(documents)){
foreach(major=major_by_doc[[i]])%do% {
cc = major_counts[[ major_map[[major]] ]]
major_counts[[ major_map[[major]] ]] = cc + 1
}
}
filtered_major_counts = major_counts[index_filter_mc]
## filter by freq_major
p=1
for (i in 1:length(documents)){
high_freq = FALSE
major_list = c()
foreach(major=major_by_doc[[i]])%do% {
if(major_counts[[major_map[[major]] ]]>THR){
high_freq = TRUE
major_list = c(major_list,major)
}
}
if(high_freq){
filtered_docs = c(filtered_docs,documents[i])
filtered_major_by_doc[[p]] = major_list
filtered_title_map = c(filtered_title_map,title_map[i])
p=p+1
}
}
